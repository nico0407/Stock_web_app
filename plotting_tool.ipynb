{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    self,\n",
    "    x_input: np.ndarray,\n",
    "    y_period: int,\n",
    "    *,\n",
    "    draw_z: bool = True,\n",
    "    quantiles=(5, 50, 95),\n",
    ") -> ForecastOutput:\n",
    "    \"\"\"Generate multi-step forecast using fitted CCC-GARCH model.\"\"\"\n",
    "\n",
    "    if not self.is_calibrated:\n",
    "        raise ValueError(\"Model must be calibrated before forecasting\")\n",
    "\n",
    "    if not hasattr(self, 'idata') or not hasattr(self, 'pivot_data'):\n",
    "        # Fallback to simple approach\n",
    "        return ForecastOutput(y_hat=[[0.0] * len(self.y_features)] * y_period)\n",
    "\n",
    "    try:\n",
    "        # ---- Build the history used by the simulator ------------------------\n",
    "        # Accept x_input as: (K, n) additional observations after calibration\n",
    "        x_input = np.asarray(x_input, dtype=float)\n",
    "        if x_input.ndim == 1:\n",
    "            x_input = x_input[np.newaxis, :]\n",
    "\n",
    "        # Scale to model’s internal units\n",
    "        scale = getattr(self, \"data_scale\", 1.0)\n",
    "        x_input_scaled = x_input / scale\n",
    "\n",
    "        # Use training history + any new rows as simulator seed\n",
    "        # self.x_full was stored at calibrate time (already scaled)\n",
    "        X_hist = self.x_full\n",
    "        if x_input_scaled.size > 0:\n",
    "            X_hist = np.vstack([self.x_full, x_input_scaled])\n",
    "\n",
    "        # ---- Simulate without premature averaging ---------------------------\n",
    "        forecasts, mu_last, sigma_last = self._simulate_ccc_garch_paths(\n",
    "            self.idata,\n",
    "            X_hist,\n",
    "            steps=y_period,\n",
    "            draw_z=draw_z,\n",
    "            seed=123,\n",
    "            rescale=True,  # bring back to original scale\n",
    "        )\n",
    "        # forecasts: (steps, S, n) in original scale\n",
    "\n",
    "        if forecasts is None or forecasts.shape[0] == 0:\n",
    "            y_hat = [[0.0] * len(self.y_features)] * y_period\n",
    "            return ForecastOutput(y_hat=y_hat)\n",
    "\n",
    "        # ---- Summaries AFTER simulation -------------------------------------\n",
    "        mean_path = forecasts.mean(axis=1)  # (steps, n)\n",
    "        qs = {q: np.percentile(forecasts, q, axis=1) for q in quantiles}  # dict[q] -> (steps, n)\n",
    "\n",
    "        # Keep your expected format: List[List[float]]\n",
    "        y_hat = [mean_path[t].tolist() for t in range(y_period)]\n",
    "\n",
    "        # If your ForecastOutput supports extra fields, attach intervals\n",
    "        extras = dict(\n",
    "            quantiles={int(q): qs[q].tolist() for q in quantiles},  # (steps, n) per quantile\n",
    "        )\n",
    "\n",
    "        return ForecastOutput(y_hat=y_hat, extras=extras)  # drop extras if your class doesn’t allow it\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Forecast generation failed: {e}\")\n",
    "        return ForecastOutput(y_hat=[[0.0] * len(self.y_features)] * y_period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    self,\n",
    "    x_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    *_, **__\n",
    ") -> ForecastEvaluationOutput:\n",
    "    \"\"\"Evaluate multi-step forecast accuracy against y_test.\"\"\"\n",
    "\n",
    "    if not self.is_calibrated:\n",
    "        raise ValueError(\"Model must be calibrated before evaluation\")\n",
    "\n",
    "    # y_test expected shape: (H, n)\n",
    "    y_test = np.asarray(y_test, dtype=float)\n",
    "    if y_test.ndim == 1:\n",
    "        y_test = y_test[np.newaxis, :]\n",
    "\n",
    "    H, n = y_test.shape\n",
    "\n",
    "    # Produce H-step forecast starting from x_test\n",
    "    fcst = self.forecast(x_test, H, draw_z=True)\n",
    "    y_hat = np.asarray(fcst.y_hat, dtype=float)  # (H, n)\n",
    "\n",
    "    if y_hat.shape != y_test.shape:\n",
    "        raise ValueError(f\"Shape mismatch: forecast {y_hat.shape} vs y_test {y_test.shape}\")\n",
    "\n",
    "    # NaN-safe RMSE\n",
    "    diff = y_hat - y_test\n",
    "    mask = np.isfinite(diff)\n",
    "    if not np.any(mask):\n",
    "        rmse = 999.0\n",
    "        per_series_rmse = [999.0] * n\n",
    "    else:\n",
    "        rmse = np.sqrt(np.nanmean((diff[mask]) ** 2))\n",
    "        per_series_rmse = np.sqrt(np.nanmean((diff) ** 2, axis=0)).tolist()\n",
    "\n",
    "    return ForecastEvaluationOutput(\n",
    "        y_hat=y_hat.tolist(),\n",
    "        error_type=ErrorType.RMSE,\n",
    "        error_value=rmse,\n",
    "        extras={\"per_series_rmse\": per_series_rmse}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_fanchart(self, forecast_output: ForecastOutput, series_index: int = 0, title=None, savepath=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    qs = forecast_output.extras.get(\"quantiles\", None) if hasattr(forecast_output, \"extras\") else None\n",
    "    y_hat = np.asarray(forecast_output.y_hat)\n",
    "\n",
    "    H = y_hat.shape[0]\n",
    "    x_axis = np.arange(1, H + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "    plt.plot(x_axis, y_hat[:, series_index], label=\"Mean forecast\")\n",
    "\n",
    "    if qs is not None:\n",
    "        q5  = np.asarray(qs[5])[:, series_index]\n",
    "        q95 = np.asarray(qs[95])[:, series_index]\n",
    "        plt.fill_between(x_axis, q5, q95, alpha=0.25, label=\"90% PI\")\n",
    "\n",
    "    plt.xlabel(\"Horizon\")\n",
    "    plt.ylabel(f\"Series {series_index}\")\n",
    "    plt.title(title or \"CCC-GARCH Forecast\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_in_sample_fit(self, idata, y_true, series_names=None):\n",
    "    \"\"\"Plot actual vs fitted values (posterior mean) for in-sample data.\"\"\"\n",
    "    mu_hat = idata.posterior['mu'].mean(dim=[\"chain\", \"draw\"]).values\n",
    "    sigma_hat = idata.posterior['sigma'].mean(dim=[\"chain\", \"draw\"]).values\n",
    "    \n",
    "    n_obs, n_series = y_true.shape\n",
    "    if series_names is None:\n",
    "        series_names = [f\"Series {i+1}\" for i in range(n_series)]\n",
    "\n",
    "    fig, axes = plt.subplots(n_series, 1, figsize=(12, 4*n_series), sharex=True)\n",
    "    if n_series == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for j in range(n_series):\n",
    "        axes[j].plot(y_true[:, j], label=\"Observed\", color=\"black\")\n",
    "        axes[j].plot(mu_hat[:, j], label=\"Fitted mean\", color=\"red\")\n",
    "        axes[j].fill_between(\n",
    "            range(n_obs),\n",
    "            mu_hat[:, j] - 2 * sigma_hat[:, j],\n",
    "            mu_hat[:, j] + 2 * sigma_hat[:, j],\n",
    "            color=\"red\", alpha=0.2, label=\"±2σ\"\n",
    "        )\n",
    "        axes[j].set_title(f\"In-sample fit: {series_names[j]}\")\n",
    "        axes[j].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(self, forecasts, y_test=None, series_names=None):\n",
    "    \"\"\"Fan chart for CCC-GARCH forecasts.\"\"\"\n",
    "    n_steps, n_series = forecasts.shape[0], forecasts.shape[2]\n",
    "    if series_names is None:\n",
    "        series_names = [f\"Series {i+1}\" for i in range(n_series)]\n",
    "\n",
    "    fig, axes = plt.subplots(n_series, 1, figsize=(12, 4*n_series), sharex=True)\n",
    "    if n_series == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for j in range(n_series):\n",
    "        forecast_dist = forecasts[:, :, j]  # shape (steps, draws)\n",
    "        p5, p50, p95 = np.percentile(forecast_dist, [5, 50, 95], axis=1)\n",
    "\n",
    "        axes[j].plot(p50, label=\"Forecast median\", color=\"blue\")\n",
    "        axes[j].fill_between(range(n_steps), p5, p95, color=\"blue\", alpha=0.2, label=\"90% CI\")\n",
    "        if y_test is not None:\n",
    "            axes[j].plot(y_test[:, j], label=\"Actual future\", color=\"black\")\n",
    "\n",
    "        axes[j].set_title(f\"Forecast: {series_names[j]}\")\n",
    "        axes[j].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "# Plot fitted mu vs observed\n",
    "mu_post = idata.posterior[\"mu\"].mean(dim=(\"chain\",\"draw\"))\n",
    "sigma_post = idata.posterior[\"sigma\"].mean(dim=(\"chain\",\"draw\"))\n",
    "\n",
    "plt.plot(Y[:,0], label=\"Observed series 1\")\n",
    "plt.plot(mu_post[:,0], label=\"Fitted mean\")\n",
    "plt.fill_between(range(len(Y)),\n",
    "                 mu_post[:,0]-2*sigma_post[:,0],\n",
    "                 mu_post[:,0]+2*sigma_post[:,0],\n",
    "                 alpha=0.2, label=\"±2σ\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv, slogdet\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ----------------------- univariate AR(5)-GARCH(1,1) ------------------------\n",
    "\n",
    "def _ar5_mean(c: float, phi: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    T = y.shape[0]\n",
    "    mu = np.empty(T)\n",
    "    mu[:5] = c\n",
    "    for t in range(5, T):\n",
    "        mu[t] = c + phi @ y[t-1:t-6:-1]\n",
    "    return mu\n",
    "\n",
    "def _garch11_var(omega: float, alpha: float, beta: float, eps: np.ndarray) -> np.ndarray:\n",
    "    T = eps.shape[0]\n",
    "    h = np.empty(T)\n",
    "    denom = max(1e-6, 1.0 - alpha - beta)\n",
    "    h[0] = max(1e-8, omega / denom)\n",
    "    for t in range(1, T):\n",
    "        h[t] = omega + alpha * eps[t-1]**2 + beta * h[t-1]\n",
    "        if h[t] < 1e-12:\n",
    "            h[t] = 1e-12\n",
    "    return h\n",
    "\n",
    "def _uv_nll(theta: np.ndarray, y: np.ndarray) -> float:\n",
    "    # theta = [c, omega, alpha, beta, phi1..phi5]\n",
    "    c, omega, alpha, beta = theta[0], theta[1], theta[2], theta[3]\n",
    "    phi = theta[4:9]\n",
    "\n",
    "    # bounds/penalties for stability\n",
    "    if omega <= 0 or alpha < 0 or beta < 0 or alpha + beta >= 0.9999:\n",
    "        return 1e12\n",
    "\n",
    "    mu = _ar5_mean(c, phi, y)\n",
    "    eps = y - mu\n",
    "    h = _garch11_var(omega, alpha, beta, eps)\n",
    "\n",
    "    t0 = 5\n",
    "    e = eps[t0:]\n",
    "    ht = h[t0:]\n",
    "    # Gaussian QMLE (drop constants)\n",
    "    nll = 0.5 * (np.log(ht).sum() + (e**2 / ht).sum())\n",
    "    return nll if np.isfinite(nll) else 1e12\n",
    "\n",
    "def _fit_univariate(y: np.ndarray) -> Dict[str, Any]:\n",
    "    # crude initials\n",
    "    c0 = 0.0\n",
    "    var = np.var(y, ddof=1)\n",
    "    omega0 = 0.05 * var if var > 0 else 1e-6\n",
    "    alpha0, beta0 = 0.05, 0.9\n",
    "    phi0 = np.zeros(5)\n",
    "    theta0 = np.r_[c0, omega0, alpha0, beta0, phi0]\n",
    "\n",
    "    bounds = [(None, None),          # c\n",
    "              (1e-10, None),         # omega\n",
    "              (1e-8, 0.999),         # alpha\n",
    "              (1e-8, 0.999)] + [(None, None)]*5  # phi1..phi5\n",
    "\n",
    "    res = minimize(_uv_nll, theta0, args=(y,),\n",
    "                   method=\"L-BFGS-B\", bounds=bounds,\n",
    "                   options={\"maxiter\": 5000, \"ftol\": 1e-9})\n",
    "\n",
    "    th = res.x\n",
    "    c, omega, alpha, beta = th[0], th[1], th[2], th[3]\n",
    "    phi = th[4:9]\n",
    "\n",
    "    mu = _ar5_mean(c, phi, y)\n",
    "    eps = y - mu\n",
    "    h = _garch11_var(omega, alpha, beta, eps)\n",
    "\n",
    "    out = {\n",
    "        \"success\": res.success,\n",
    "        \"message\": res.message,\n",
    "        \"nll\": float(res.fun),\n",
    "        \"params\": {\"c\": c, \"omega\": omega, \"alpha\": alpha, \"beta\": beta, \"phi\": phi},\n",
    "        \"mu\": mu,                # (T,)\n",
    "        \"h\": h,                  # (T,)\n",
    "        \"vol\": np.sqrt(h),       # (T,)\n",
    "        \"eps\": eps               # (T,)\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# ----------------------- CCC two-step wrapper -------------------------------\n",
    "\n",
    "@dataclass\n",
    "class CCCTwoStepResults:\n",
    "    success: bool\n",
    "    messages: list[str]\n",
    "    univariate: list[Dict[str, Any]]\n",
    "    R: np.ndarray                 # (N, N)\n",
    "    std_resids: np.ndarray        # (T_eff, N)\n",
    "    H: np.ndarray                 # (T_eff, N, N)\n",
    "    cond_means: np.ndarray        # (T, N)\n",
    "    cond_vars: np.ndarray         # (T, N)\n",
    "    cond_vols: np.ndarray         # (T, N)\n",
    "    T_eff: int\n",
    "    start_index: int\n",
    "    loglike_full: float           # multivariate (concentrated) log-likelihood (up to const)\n",
    "\n",
    "class CCCGARCHTwoStep:\n",
    "    \"\"\"\n",
    "    Classic CCC-GARCH with two-step calibration:\n",
    "      Step 1: Fit AR(5)-GARCH(1,1) per series (QMLE).\n",
    "      Step 2: Standardize residuals, set R = sample correlation(Z).\n",
    "              Build H_t = D_t R D_t and compute multivariate log-likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.assets: list[str] = []\n",
    "        self.dates: pd.Index | None = None\n",
    "        self.Y: np.ndarray | None = None\n",
    "        self.T: int | None = None\n",
    "        self.N: int | None = None\n",
    "        self.result_: CCCTwoStepResults | None = None\n",
    "\n",
    "    def spec(self, returns: pd.DataFrame) -> None:\n",
    "        self.assets = list(returns.columns)\n",
    "        self.dates = returns.index\n",
    "        self.Y = returns.to_numpy(float)\n",
    "        self.T, self.N = self.Y.shape\n",
    "\n",
    "    @staticmethod\n",
    "    def _safe_corr(Z: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "        R = np.corrcoef(Z, rowvar=False)\n",
    "        R = (1 - eps) * R + eps * np.eye(R.shape[0])  # SPD ridge\n",
    "        return R\n",
    "\n",
    "    def fit(self) -> CCCTwoStepResults:\n",
    "        assert self.Y is not None, \"Call .spec(returns) first.\"\n",
    "        T, N = self.T, self.N\n",
    "        t0 = 5  # burn-in due to AR(5)\n",
    "\n",
    "        # Step 1: univariate fits\n",
    "        uni = []\n",
    "        for i in range(N):\n",
    "            uni.append(_fit_univariate(self.Y[:, i]))\n",
    "\n",
    "        MU = np.column_stack([u[\"mu\"] for u in uni])     # (T, N)\n",
    "        Hdiag = np.column_stack([u[\"h\"] for u in uni])   # (T, N)\n",
    "        VOL = np.sqrt(Hdiag)\n",
    "        EPS = self.Y - MU\n",
    "\n",
    "        # Step 2: CCC — standardized residuals and correlation\n",
    "        Z = EPS[t0:, :] / VOL[t0:, :]\n",
    "        R = self._safe_corr(Z)\n",
    "        sign, logdetR = slogdet(R)\n",
    "        if sign <= 0:\n",
    "            raise RuntimeError(\"Correlation matrix not SPD.\")\n",
    "\n",
    "        # H_t for t >= t0\n",
    "        Te = T - t0\n",
    "        H = np.zeros((Te, N, N))\n",
    "        for t in range(Te):\n",
    "            Dt = np.diag(VOL[t0 + t, :])\n",
    "            H[t] = Dt @ R @ Dt\n",
    "\n",
    "        # (Concentrated) multivariate Gaussian log-likelihood (up to constants)\n",
    "        # sum_t [ -0.5*( log|H_t| + e_t' H_t^{-1} e_t ) ]\n",
    "        # with log|H_t| = sum_i log h_{i,t} + log|R|\n",
    "        logh_sum = np.log(Hdiag[t0:, :]).sum()\n",
    "        quad = 0.0\n",
    "        Rinv = inv(R)\n",
    "        for t in range(Te):\n",
    "            zt = Z[t, :]\n",
    "            quad += zt @ Rinv @ zt\n",
    "        ll = -0.5 * (Te * logdetR + logh_sum + quad)\n",
    "\n",
    "        self.result_ = CCCTwoStepResults(\n",
    "            success=all(u[\"success\"] for u in uni),\n",
    "            messages=[u[\"message\"] for u in uni],\n",
    "            univariate=uni,\n",
    "            R=R,\n",
    "            std_resids=Z,\n",
    "            H=H,\n",
    "            cond_means=MU,\n",
    "            cond_vars=Hdiag,\n",
    "            cond_vols=VOL,\n",
    "            T_eff=Te,\n",
    "            start_index=t0,\n",
    "            loglike_full=float(ll),\n",
    "        )\n",
    "        return self.result_\n",
    "\n",
    "    def forecast(self, n_ahead: int = 1) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Mean-path forecasts:\n",
    "          mu_{t+k|t}: iterate AR(5) using last observed y\n",
    "          h_{t+k|t}: iterate GARCH(1,1) with eps_t^2, h_t from last time\n",
    "          R is constant (CCC)\n",
    "          H_{t+k|t} = D_{t+k|t} R D_{t+k|t}\n",
    "        \"\"\"\n",
    "        assert self.result_ is not None, \"Fit the model first.\"\n",
    "        Y = self.Y\n",
    "        T, N = self.T, self.N\n",
    "        p = 5\n",
    "        R = self.result_.R\n",
    "\n",
    "        Cs = np.array([u[\"params\"][\"c\"] for u in self.result_.univariate])\n",
    "        Om = np.array([u[\"params\"][\"omega\"] for u in self.result_.univariate])\n",
    "        Al = np.array([u[\"params\"][\"alpha\"] for u in self.result_.univariate])\n",
    "        Be = np.array([u[\"params\"][\"beta\"] for u in self.result_.univariate])\n",
    "        Ph = np.vstack([u[\"params\"][\"phi\"] for u in self.result_.univariate])\n",
    "\n",
    "        mu_hist = self.result_.cond_means\n",
    "        h_hist  = self.result_.cond_vars\n",
    "        eps_hist = Y - mu_hist\n",
    "\n",
    "        mu_fc = np.zeros((n_ahead, N))\n",
    "        var_fc = np.zeros((n_ahead, N))\n",
    "\n",
    "        y_buf = Y.copy()\n",
    "        h_t = h_hist[-1, :].copy()\n",
    "        eps2_t = eps_hist[-1, :]**2\n",
    "\n",
    "        for k in range(n_ahead):\n",
    "            y_hist = y_buf[-p:, :]  # shape (5,N)\n",
    "            for i in range(N):\n",
    "                mu_fc[k, i] = Cs[i] + Ph[i] @ y_hist[::-1, i]\n",
    "            var_fc[k, :] = Om + Al * eps2_t + Be * h_t\n",
    "            # advance with mean path\n",
    "            y_buf = np.vstack([y_buf, mu_fc[k, :]])\n",
    "            eps2_t = 0.0 * eps2_t\n",
    "            h_t = var_fc[k, :]\n",
    "\n",
    "        vol_fc = np.sqrt(np.maximum(var_fc, 1e-12))\n",
    "        cov_fc = np.zeros((n_ahead, N, N))\n",
    "        for k in range(n_ahead):\n",
    "            Dk = np.diag(vol_fc[k, :])\n",
    "            cov_fc[k] = Dk @ R @ Dk\n",
    "\n",
    "        return {\"mu\": mu_fc, \"var\": var_fc, \"vol\": vol_fc, \"cov\": cov_fc, \"R\": R}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: N806\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import TYPE_CHECKING, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import cholesky, cho_solve\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    pass\n",
    "\n",
    "\n",
    "class DCCGARCHFullMLE:\n",
    "    \"\"\"\n",
    "    Full-information MLE for DCC-GARCH with AR(5)-GARCH(1,1) margins.\n",
    "\n",
    "    Fits AR(5) + GARCH(1,1) parameters for each asset and DCC (a,b)\n",
    "    in one joint optimization by minimizing the entire multivariate\n",
    "    Gaussian negative log-likelihood.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eps_sum: float = 1e-4, eps_dcc: float = 1e-4, ar_stability_weight: float = 10.0):\n",
    "        # data\n",
    "        self.assets: list[str] = []\n",
    "        self.dates: pd.Index | None = None\n",
    "        self._returns: np.ndarray | None = None\n",
    "        self.n_periods: int | None = None\n",
    "        self.n_assets: int | None = None\n",
    "        self.p_ar: int = 5\n",
    "\n",
    "        # fitted time-varying stuff\n",
    "        self.cond_means: np.ndarray | None = None       # (T, N)\n",
    "        self.resids: np.ndarray | None = None           # (T, N)\n",
    "        self.cond_vols: np.ndarray | None = None        # (T, N)\n",
    "        self.std_resids: np.ndarray | None = None       # (T, N)\n",
    "        self.cond_cor: np.ndarray | None = None         # (N, N, T)\n",
    "        self.cond_cov: np.ndarray | None = None         # (N, N, T)\n",
    "\n",
    "        # parameters (after fit)\n",
    "        self.ar_params: np.ndarray | None = None        # (N, 1 + p) -> [c, phi1..phi5]\n",
    "        self.garch_params: np.ndarray | None = None     # (N, 3) -> [omega, alpha, beta]\n",
    "        self.dcc_a: float | None = None\n",
    "        self.dcc_b: float | None = None\n",
    "\n",
    "        # reparam epsilons / penalties\n",
    "        self._eps_sum = eps_sum\n",
    "        self._eps_dcc = eps_dcc\n",
    "        self._ar_stab_w = ar_stability_weight\n",
    "\n",
    "    # ------------------------\n",
    "    # Data plumbing\n",
    "    # ------------------------\n",
    "    @property\n",
    "    def returns(self) -> np.ndarray:\n",
    "        return self._returns\n",
    "\n",
    "    @returns.setter\n",
    "    def returns(self, returns: pd.DataFrame) -> None:\n",
    "        self._returns = returns.to_numpy(dtype=float)\n",
    "        self.assets = returns.columns.to_list()\n",
    "        self.n_assets = len(self.assets)\n",
    "        self.n_periods = len(returns)\n",
    "        self.dates = returns.index\n",
    "\n",
    "    def spec(self, returns: pd.DataFrame) -> None:\n",
    "        \"\"\"Load the data and prep dimensions.\"\"\"\n",
    "        self.returns = returns\n",
    "        if self.p_ar >= self.n_periods:\n",
    "            raise ValueError(\"Not enough observations for AR(5).\")\n",
    "\n",
    "    # ------------------------\n",
    "    # Helpers: parameter pack/unpack with constraints\n",
    "    # ------------------------\n",
    "    @staticmethod\n",
    "    def _inv_logit(x: np.ndarray) -> np.ndarray:\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    def _unpack_params(self, theta: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, float, float]:\n",
    "        \"\"\"\n",
    "        Map raw vector to structured, *constrained* parameters.\n",
    "\n",
    "        Per asset i:\n",
    "          [c_i, phi_i1..phi_i5, log_omega_i, u_i, v_i]\n",
    "            -> omega_i = exp(log_omega_i)\n",
    "            -> alpha_i = (1-eps) * u_i\n",
    "            -> beta_i  = (1-eps-alpha_i) * v_i\n",
    "\n",
    "        DCC tail:\n",
    "          [u_a, v_b]\n",
    "            -> a = (1-eps_dcc) * u_a\n",
    "            -> b = (1-eps_dcc - a) * v_b\n",
    "        \"\"\"\n",
    "        N = self.n_assets\n",
    "        p = self.p_ar\n",
    "        num_per_asset = 1 + p + 3  # c + 5 phi + (log_omega, u, v)\n",
    "        expected_len = N * num_per_asset + 2\n",
    "        if theta.size != expected_len:\n",
    "            raise ValueError(f\"Parameter length mismatch (got {theta.size}, expected {expected_len}).\")\n",
    "\n",
    "        # Split\n",
    "        block = theta[: N * num_per_asset].reshape(N, num_per_asset)\n",
    "        tail = theta[N * num_per_asset :]\n",
    "\n",
    "        c = block[:, 0]\n",
    "        phis = block[:, 1 : 1 + p]                      # (N, 5)\n",
    "\n",
    "        log_omega = block[:, 1 + p]\n",
    "        u_alpha_raw = block[:, 2 + p]\n",
    "        v_beta_raw = block[:, 3 + p]\n",
    "\n",
    "        omega = np.exp(log_omega)\n",
    "        u_alpha = self._inv_logit(u_alpha_raw)\n",
    "        v_beta = self._inv_logit(v_beta_raw)\n",
    "\n",
    "        alpha = (1.0 - self._eps_sum) * u_alpha\n",
    "        beta = (1.0 - self._eps_sum - alpha) * v_beta\n",
    "\n",
    "        # DCC params\n",
    "        u_a = self._inv_logit(tail[0])\n",
    "        v_b = self._inv_logit(tail[1])\n",
    "        a = (1.0 - self._eps_dcc) * u_a\n",
    "        b = (1.0 - self._eps_dcc - a) * v_b\n",
    "\n",
    "        return c, phis, np.column_stack([omega, alpha, beta]), float(a), float(b)\n",
    "\n",
    "    def _initial_theta(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Simple, robust initial values:\n",
    "          c=0, phi=0, omega from var*0.1, alpha≈0.05, beta≈0.9 (sum<1)\n",
    "          DCC: a≈0.02, b≈0.95\n",
    "        \"\"\"\n",
    "        N = self.n_assets\n",
    "        p = self.p_ar\n",
    "        num_per_asset = 1 + p + 3\n",
    "\n",
    "        var = self._returns.var(axis=0, ddof=1)\n",
    "        omega0 = np.maximum(1e-8, 0.1 * var)          # positive\n",
    "        alpha0 = 0.05 * np.ones(N)\n",
    "        beta0 = np.minimum(0.9, 0.94 - alpha0)        # keep sum < 0.99\n",
    "        # invert transforms\n",
    "        log_omega0 = np.log(omega0)\n",
    "        # alpha = (1-eps)*u -> u = alpha/(1-eps)\n",
    "        u_alpha0 = np.clip(alpha0 / (1.0 - self._eps_sum), 1e-6, 1 - 1e-6)\n",
    "        v_beta0 = np.clip(beta0 / (1.0 - self._eps_sum - alpha0), 1e-6, 1 - 1e-6)\n",
    "        u_alpha_raw0 = np.log(u_alpha0 / (1.0 - u_alpha0))\n",
    "        v_beta_raw0 = np.log(v_beta0 / (1.0 - v_beta0))\n",
    "\n",
    "        # AR starts at zero (including intercept)\n",
    "        c0 = np.zeros(N)\n",
    "        phis0 = np.zeros((N, p))\n",
    "\n",
    "        block = np.column_stack([c0, phis0, log_omega0, u_alpha_raw0, v_beta_raw0])  # (N, 1+p+3)\n",
    "\n",
    "        # DCC init: a=0.02, b=0.95\n",
    "        a0, b0 = 0.02, 0.95\n",
    "        u_a0 = np.clip(a0 / (1.0 - self._eps_dcc), 1e-6, 1 - 1e-6)\n",
    "        v_b0 = np.clip(b0 / (1.0 - self._eps_dcc - a0), 1e-6, 1 - 1e-6)\n",
    "        tail = np.array([\n",
    "            np.log(u_a0 / (1.0 - u_a0)),\n",
    "            np.log(v_b0 / (1.0 - v_b0)),\n",
    "        ])\n",
    "\n",
    "        return np.concatenate([block.reshape(-1), tail])\n",
    "\n",
    "    # ------------------------\n",
    "    # Core likelihood machinery\n",
    "    # ------------------------\n",
    "    def _compute_conditional_means(self, c: np.ndarray, phis: np.ndarray) -> np.ndarray:\n",
    "        T, N = self.n_periods, self.n_assets\n",
    "        p = self.p_ar\n",
    "        r = self._returns\n",
    "        mu = np.zeros((T, N), dtype=float)\n",
    "        for t in range(p, T):\n",
    "            # mu_t = c + sum_{k=1..p} phi_k * r_{t-k}\n",
    "            mu[t, :] = c + np.sum(phis * r[t - np.arange(1, p + 1)[:, None], :].T[:, ::-1][:, ::-1], axis=1)\n",
    "            # The above indexing keeps it simple & explicit.\n",
    "            # Alternatively:\n",
    "            # mu[t, :] = c + (phis * r[t-1:t-p-1:-1, :].T).sum(axis=1)\n",
    "        # first p means remain 0 (condition on initial lags)\n",
    "        return mu\n",
    "\n",
    "    def _compute_garch_vols(self, resids: np.ndarray, gpars: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"resids: (T,N) -> h: (T,N) using GARCH(1,1) recursion.\"\"\"\n",
    "        T, N = resids.shape\n",
    "        h = np.zeros_like(resids)\n",
    "        for i in range(N):\n",
    "            omega, alpha, beta = gpars[i]\n",
    "            # Start h[0] at unconditional variance as a stable default\n",
    "            var0 = np.var(resids[:, i], ddof=1)\n",
    "            h_t = omega + alpha * (resids[0, i] ** 2 if np.isfinite(resids[0, i]) else 0.0) + beta * max(var0, 1e-8)\n",
    "            h[0, i] = max(h_t, 1e-10)\n",
    "            for t in range(1, T):\n",
    "                h[t, i] = omega + alpha * (resids[t - 1, i] ** 2) + beta * h[t - 1, i]\n",
    "                if h[t, i] <= 1e-12:\n",
    "                    h[t, i] = 1e-12  # numerical floor\n",
    "        return h\n",
    "\n",
    "    @staticmethod\n",
    "    def _ar_stability_penalty(phis_row: np.ndarray) -> float:\n",
    "        \"\"\"Penalize if any AR root is inside unit circle.\"\"\"\n",
    "        # AR poly: 1 - phi1 z - ... - phi_p z^p\n",
    "        coeffs = np.concatenate([[1.0], -phis_row])\n",
    "        try:\n",
    "            roots = np.roots(coeffs)\n",
    "            min_mod = np.min(np.abs(roots)) if roots.size else 1.0\n",
    "        except Exception:\n",
    "            min_mod = 0.0\n",
    "        if min_mod <= 1.0:\n",
    "            return (1.0 - min_mod + 1e-6) ** 2\n",
    "        return 0.0\n",
    "\n",
    "    def _dcc_recursion(self, u: np.ndarray, a: float, b: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        u: standardized residuals (T,N)\n",
    "        returns: R (N,N,T), H (N,N,T) is built elsewhere using D\n",
    "        \"\"\"\n",
    "        T, N = u.shape\n",
    "        Qbar = np.cov(u.T, bias=False)\n",
    "        Q = np.zeros((N, N, T))\n",
    "        R = np.zeros_like(Q)\n",
    "        # initialize with Qbar\n",
    "        Q[:, :, 0] = Qbar\n",
    "        for t in range(1, T):\n",
    "            utm1 = u[t - 1][:, None]\n",
    "            Q[:, :, t] = (1.0 - a - b) * Qbar + a * (utm1 @ utm1.T) + b * Q[:, :, t - 1]\n",
    "        # Normalize to correlations\n",
    "        for t in range(T):\n",
    "            d = np.sqrt(np.clip(np.diag(Q[:, :, t]), 1e-12, np.inf))\n",
    "            Dinv = np.diag(1.0 / d)\n",
    "            R[:, :, t] = Dinv @ Q[:, :, t] @ Dinv\n",
    "        return R, Q\n",
    "\n",
    "    def _negloglik(self, theta: np.ndarray) -> float:\n",
    "        try:\n",
    "            c, phis, gpars, a, b = self._unpack_params(theta)\n",
    "            # mild AR stability penalty across assets\n",
    "            pen = self._ar_stab_w * sum(self._ar_stability_penalty(phis[i]) for i in range(self.n_assets))\n",
    "\n",
    "            # conditional means and residuals\n",
    "            mu = self._compute_conditional_means(c, phis)\n",
    "            e = self._returns - mu\n",
    "            # drop first p obs (conditioning)\n",
    "            e = e[self.p_ar :, :]\n",
    "            T_eff = e.shape[0]\n",
    "            if T_eff <= 2:\n",
    "                return 1e12\n",
    "\n",
    "            # GARCH volatilities\n",
    "            h = self._compute_garch_vols(e, gpars)  # (T_eff,N)\n",
    "            u = e / np.sqrt(h)\n",
    "\n",
    "            # DCC recursion -> correlations\n",
    "            R, _ = self._dcc_recursion(u, a, b)\n",
    "\n",
    "            # Build H_t = D_t R_t D_t and accumulate Gaussian nll\n",
    "            nll = 0.0\n",
    "            for t in range(T_eff):\n",
    "                D = np.diag(np.sqrt(h[t, :]))\n",
    "                H = D @ R[:, :, t] @ D\n",
    "\n",
    "                # Cholesky for stability\n",
    "                L = cholesky(H, lower=True, check_finite=False)\n",
    "                # log |H| = 2 * sum log diag(L)\n",
    "                logdet = 2.0 * np.sum(np.log(np.diag(L)))\n",
    "                # quadratic form via solves\n",
    "                q = cho_solve((L, True), e[t, :], check_finite=False)\n",
    "                quad = float(e[t, :].T @ q)\n",
    "\n",
    "                nll += 0.5 * (logdet + quad)\n",
    "\n",
    "            return nll + pen\n",
    "        except (FloatingPointError, LinAlgError, ValueError) as _:\n",
    "            return 1e12\n",
    "\n",
    "    # ------------------------\n",
    "    # Public API\n",
    "    # ------------------------\n",
    "    def fit(self, options: dict | None = None) -> None:\n",
    "        \"\"\"\n",
    "        Jointly estimate AR(5), GARCH(1,1) per asset and DCC (a,b)\n",
    "        by minimizing the full negative log-likelihood.\n",
    "        \"\"\"\n",
    "        if self._returns is None:\n",
    "            raise RuntimeError(\"Call .spec(returns) first.\")\n",
    "\n",
    "        theta0 = self._initial_theta()\n",
    "        result = minimize(\n",
    "            fun=self._negloglik,\n",
    "            x0=theta0,\n",
    "            method=\"L-BFGS-B\",\n",
    "            options={\"maxiter\": 10_000, \"disp\": False, **(options or {})},\n",
    "        )\n",
    "\n",
    "        # unpack & store\n",
    "        c, phis, gpars, a, b = self._unpack_params(result.x)\n",
    "        self.ar_params = np.column_stack([c, phis])                # (N, 1+5)\n",
    "        self.garch_params = gpars                                   # (N, 3)\n",
    "        self.dcc_a, self.dcc_b = a, b\n",
    "\n",
    "        # build full state with fitted params for later use / plotting\n",
    "        mu_full = self._compute_conditional_means(c, phis)\n",
    "        e_full = self._returns - mu_full\n",
    "        e_eff = e_full[self.p_ar :, :]\n",
    "        h_eff = self._compute_garch_vols(e_eff, gpars)\n",
    "        u_eff = e_eff / np.sqrt(h_eff)\n",
    "        R_eff, _ = self._dcc_recursion(u_eff, a, b)\n",
    "\n",
    "        # store with original T alignment (pad first p with NaN)\n",
    "        T, N = self.n_periods, self.n_assets\n",
    "        self.cond_means = mu_full\n",
    "        self.resids = np.full((T, N), np.nan)\n",
    "        self.resids[self.p_ar :, :] = e_eff\n",
    "        self.cond_vols = np.full((T, N), np.nan)\n",
    "        self.cond_vols[self.p_ar :, :] = np.sqrt(h_eff)\n",
    "        self.std_resids = np.full((T, N), np.nan)\n",
    "        self.std_resids[self.p_ar :, :] = u_eff\n",
    "\n",
    "        self.cond_cor = np.zeros((N, N, T))\n",
    "        self.cond_cor[:, :, : self.p_ar] = np.nan\n",
    "        self.cond_cor[:, :, self.p_ar :] = R_eff\n",
    "\n",
    "        self.cond_cov = np.zeros((N, N, T))\n",
    "        for t in range(T):\n",
    "            if t < self.p_ar or not np.isfinite(self.cond_vols[t, :]).all():\n",
    "                self.cond_cov[:, :, t] = np.nan\n",
    "            else:\n",
    "                D = np.diag(self.cond_vols[t, :])\n",
    "                self.cond_cov[:, :, t] = D @ self.cond_cor[:, :, t] @ D\n",
    "\n",
    "    # Compatibility helpers (names you used before)\n",
    "    @property\n",
    "    def phis(self) -> np.ndarray | None:  # shape (N, 5)\n",
    "        return self.ar_params[:, 1:] if self.ar_params is not None else None\n",
    "\n",
    "    @property\n",
    "    def thetas(self) -> np.ndarray | None:\n",
    "        # Keeping for compatibility: ARMA \"thetas\" were MA(1); here unused.\n",
    "        return np.zeros_like(self.phis) if self.ar_params is not None else None\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"\n",
    "        You can plug in your existing plotting routine.\n",
    "        This class exposes:\n",
    "          - self.cond_vols  (T,N)\n",
    "          - self.cond_cor   (N,N,T)\n",
    "          - self.assets, self.dates\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.dates as mdates\n",
    "\n",
    "        if self.cond_vols is None or self.cond_cor is None:\n",
    "            raise RuntimeError(\"Fit the model first.\")\n",
    "\n",
    "        N = self.n_assets\n",
    "        fig, axes = plt.subplots(nrows=N, ncols=N, figsize=(9, 6), sharex=True)\n",
    "        fig.tight_layout()\n",
    "        plt.subplots_adjust(left=0.05, right=0.95, bottom=0.08, top=0.9, hspace=0.3)\n",
    "        fig.suptitle(\n",
    "            \"Full-MLE DCC-GARCH fit.\\n\"\n",
    "            \"Conditional volatilities on diagonal; conditional correlations off-diagonal\"\n",
    "        )\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                ax = axes[i, j]\n",
    "                if i == j:\n",
    "                    ax.plot(self.dates, self.cond_vols[:, i])\n",
    "                    ax.set_title(self.assets[i])\n",
    "                elif i > j:\n",
    "                    ax.plot(self.dates, self.cond_cor[i, j, :], lw=0.9)\n",
    "                    ax.set_title(f\"{self.assets[i]} : {self.assets[j]}\")\n",
    "                else:\n",
    "                    ax.axis(\"off\")\n",
    "                ax.xaxis.set_major_locator(mdates.YearLocator(3))\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "                for lab in ax.get_xticklabels(which=\"major\"):\n",
    "                    lab.set(rotation=30, horizontalalignment=\"right\")\n",
    "        plt.show()\n",
    "        return axes\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# returns: pd.DataFrame with columns = assets, index = dates\n",
    "model = DCCGARCHFullMLE()\n",
    "model.spec(returns)\n",
    "model.fit()\n",
    "\n",
    "# Results:\n",
    "model.ar_params       # (N, 6): [c, phi1..phi5]\n",
    "model.garch_params    # (N, 3): [omega, alpha, beta]\n",
    "model.dcc_a, model.dcc_b\n",
    "model.cond_means      # (T, N)\n",
    "model.cond_vols       # (T, N)  -- conditional std devs\n",
    "model.std_resids      # (T, N)\n",
    "model.cond_cor        # (N, N, T)\n",
    "model.cond_cov        # (N, N, T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
